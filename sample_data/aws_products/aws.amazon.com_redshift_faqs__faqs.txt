General
To find out what’s new with Amazon Redshift, visit the What’s New page. To view more detailed information and usage guidance, visit the Documentation.
Q: What is Amazon Redshift?
Amazon Redshift is the most widely used cloud data warehouse. It makes it fast, simple and cost-effective to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. It allows you to run complex analytic queries against terabytes to petabytes of structured and semi-structured data, using sophisticated query optimization, columnar storage on high-performance storage, and massively parallel query execution. Most results come back in seconds. With Redshift, you can start small for just $0.25 per hour with no commitments and scale out to petabytes of data for $1,000 per terabyte per year, less than a tenth the cost of traditional on-premises solutions. Amazon Redshift also includes Amazon Redshift Spectrum, allowing you to run SQL queries directly against exabytes of unstructured data in Amazon S3 data lakes. No loading or transformation is required, and you can use open data formats, including Avro, CSV, Grok, Amazon Ion, JSON, ORC, Parquet, RCFile, RegexSerDe, Sequence, Text, Hudi, Delta and TSV. Redshift Spectrum automatically scales query compute capacity based on the data retrieved, so queries against Amazon S3 run fast, regardless of data set size.
Amazon Redshift gives you fast querying capabilities over structured data using familiar SQL-based clients and business intelligence (BI) tools using standard ODBC and JDBC connections. Queries are distributed and parallelized across multiple physical resources. You can easily scale an Amazon Redshift data warehouse up or down with a few clicks in the AWS Management Console or with a single API call. Amazon Redshift automatically patches and backs up your data warehouse, storing the backups for a user-defined retention period. Amazon Redshift uses replication and continuous backups to enhance availability and improve data durability and can automatically recover from component and node failures. In addition, Amazon Redshift supports industry-leading security with AWS IAM integration, identity federation, column-level access control, Amazon Virtual Private Cloud (Amazon VPC), SSL, AES-256 encryption, and built-in AWS KMS integration to protect your data in transit and at rest. All Amazon Redshift security features are included with no additional costs.
Amazon Redshift integrates with AWS CloudTrail to enable you to audit all Redshift API calls. Redshift logs all SQL operations, including connection attempts, queries, and changes to your data warehouse. You can access these logs using SQL queries against system tables, or choose to save the logs to a secure location in Amazon S3. Amazon Redshift is compliant with SOC1, SOC2, SOC3, and PCI DSS Level 1 requirements.
As with all Amazon Web Services, there are no up-front investments required, and you pay only for the resources you use. Amazon Redshift lets you pay as you go. You can even try Amazon Redshift for free.
For information about Amazon Redshift regional availability, see the AWS Region Table.
Q: Why would I use Amazon Redshift over an on-premises data warehouse?
On-premises data warehouses require significant time and resource to administer, especially for large datasets. In addition, the financial costs associated with building, maintaining, and growing self-managed, on-premises data warehouses are very high. As your data grows, you have to constantly trade-off what data to load into your data warehouse and what data to archive in storage so you can manage costs, keep ETL complexity low, and deliver good performance. Amazon Redshift not only significantly lowers the cost and operational overhead of a data warehouse, but with Redshift Spectrum, it also makes it easy to analyze large amounts of data in its native format without requiring you to load the data.
Q: What is AQUA (Advanced Query Accelerator) for Amazon Redshift?
AQUA is a new distributed and hardware-accelerated cache that enables Redshift to run up to 10x faster than any other enterprise cloud data warehouse. Existing data warehousing architectures with centralized storage require data be moved to compute clusters for processing. As data warehouses continue to grow over the next few years, the network bandwidth needed to move all this data becomes a bottleneck on query performance.
AQUA takes a new approach to cloud data warehousing. AQUA brings the compute to storage by doing a substantial share of data processing in-place on the innovative cache. In addition, it uses AWS-designed processors and a scale-out architecture to accelerate data processing beyond anything traditional CPUs can do today. Learn more.
Q: Which node types support AQUA?
AQUA is supported on the RA3 .16XL and RA3 .4XL node types. If you are currently using DS2 or DC2 node types, you must first upgrade to RA3 .16XL or RA3 .4XL node types to take advantage of AQUA’s query acceleration.
Q: How will I be charged and billed for my use of AQUA?
AQUA is included with the Redshift RA3 instance type at no additional cost. Details on RA3 node pricing is available here.
Q: How do I enable/disable AQUA for my Redshift data warehouse?
For Redshift clusters running on RA3 nodes, you can enable/disable AQUA at the cluster-level using the Redshift console, CLI, or API. The cluster will have to be restarted for the setting to take effect. For Redshift clusters running on DC, DS, or older generation nodes, you must upgrade to RA3 nodes first and enable/disable AQUA. The default setting for AQUA is Automatic so Redshift determines if AQUA is enabled/disabled. This setting is a cluster-level property so once set it applies to all databases, schemas, and queries on the cluster.
Q: What type of queries are accelerated by AQUA?
AQUA accelerates analytics queries by running data intensive tasks such as scans, filtering, and aggregation closer to the storage layer using purpose-built hardware. You’ll see the most noticeable performance improvement on queries that require large scans, especially those with LIKE and SIMILAR_TO predicates. Over time the types of queries that are accelerated by AQUA will increase.
Q: How does AQUA keeps my data secure?
AQUA supports authentication, encryption, isolation, and compliance to keep your data at rest and in motion secure. Authentication is handled by Redshift using the AWS IAM authentication service. For encryption, AQUA uses TLS encrypted channel along with customer provided keys to keep data in motion and at rest in cache secure.
Q: How do I know which queries on my Redshift cluster are accelerated by AQUA?
You can query the system tables to see the queries accelerated by AQUA.
Q: What is Redshift Spectrum?
Redshift Spectrum is a feature of Amazon Redshift that enables you to run queries against exabytes of unstructured data in Amazon S3, with no loading or ETL required. When you issue a query, it goes to the Amazon Redshift SQL endpoint, which generates and optimizes a query plan. Amazon Redshift determines what data is local and what is in Amazon S3, generates a plan to minimize the amount of Amazon S3 data that needs to be read, requests Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3.
Redshift Spectrum scales out to thousands of instances if needed, so queries run quickly regardless of data size. In addition, you can use the exact same SQL for Amazon S3 data as you do for your Amazon Redshift queries and connect to the same Amazon Redshift endpoint using your same BI tools. Redshift Spectrum lets you separate storage and compute, allowing you to scale each independently. You can setup as many Amazon Redshift clusters as you need to query your Amazon S3 data lake, providing high availability and limitless concurrency. Redshift Spectrum gives you the freedom to store your data where you want, in the format you want, and have it available for processing when you need it. For information about Redshift Spectrum regional availability, please visit the Amazon Redshift pricing page.
Q: How is AQUA different from using Redshift Spectrum?
Redshift Spectrum is designed to allow queries over open formats stored in Amazon S3. The open formats can be queried by multiple engines including Amazon EMR which supports Apache Spark, or Amazon Athena which supports a serverless experience. Redshift Spectrum does not support transactional updates and does not support the optimized native Redshift format used to store data ingested in Redshift. Using Redshift Spectrum requires explicit definition of an external table whereas AQUA operates on native Redshift tables. Spectrum is great for running infrequent queries on cold data in an integrated way from your Redshift cluster.
AQUA accelerates Redshift’s ability to SCAN and AGGREGATE large volumes of data that are part of your Redshift database. Even when leveraging AQUA, Redshift maintains support for transactions, and AQUA will always operate on the latest data.
Q: What is Amazon Redshift managed storage?
Amazon Redshift managed storage is available with RA3 node types and enables you to scale and pay for compute and storage independently so you can size your cluster based only on your compute needs. It automatically uses high-performance SSD based local storage as tier-1 cache and takes advantage of optimizations such as data block temperature, data block age, and workload patterns to deliver high performance while scaling storage automatically to Amazon S3 when needed without requiring any action.
Q: How do I use Amazon Redshift’s managed storage?
If you are already using Amazon Redshift DS or DC node nodes, you can upgrade your existing clusters to the new compute instance RA3 to use managed storage. You can also create a new cluster based on the RA3 instance and managed storage is automatically included. No other action is required to use this capability.
Q: How does Amazon Redshift simplify data warehouse management?
Amazon Redshift manages the work needed to set up, operate, and scale a data warehouse. For example, provisioning the infrastructure capacity, automating ongoing administrative tasks such as backups, and patching, and monitoring nodes and drives to recover from failures. Redshift also has automatic tuning capabilities, and surfaces recommendations for managing your warehouse in Redshift Advisor. For Redshift Spectrum, Amazon Redshift manages all the computing infrastructure, load balancing, planning, scheduling and execution of your queries on data stored in Amazon S3.
Q: How does the performance of Amazon Redshift compare to most on-premises databases for data warehousing and analytics?
Amazon Redshift uses a variety of innovations to achieve up to ten times better performance than traditional databases for data warehousing and analytics workloads, they include the following:
Columnar Data Storage: Instead of storing data as a series of rows, Amazon Redshift organizes the data by column. Unlike row-based systems, which are ideal for transaction processing, column-based systems are ideal for data warehousing and analytics, where queries often involve aggregates performed over large data sets. Since only the columns involved in the queries are processed and columnar data is stored sequentially on the storage media, column-based systems require far fewer I/Os, greatly improving query performance.
Advanced Compression: Columnar data stores can be compressed much more than row-based data stores because similar data is stored sequentially on disk. Amazon Redshift employs multiple compression techniques and can often achieve significant compression relative to traditional relational data stores. When loading data into an empty table, Amazon Redshift automatically samples your data and selects the most appropriate compression scheme.
Massively Parallel Processing (MPP): Amazon Redshift automatically distributes data and query load across all nodes. Amazon Redshift makes it easy to add nodes to your data warehouse and enables you to maintain fast query performance as your data warehouse grows.
Redshift Spectrum: Redshift Spectrum enables you to run queries against exabytes of data in Amazon S3. There is no loading or ETL required. Even if you don’t store any of your data in Amazon Redshift, you can still use Redshift Spectrum to query datasets as large as an exabyte in Amazon S3. When you issue a query, it goes to the Amazon Redshift SQL endpoint, which generates the query plan. Amazon Redshift determines what data is local and what is in Amazon S3, generates a plan to minimize the amount of Amazon S3 data that needs to be read, requests Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3, and pulls results back into your Amazon Redshift cluster for any remaining processing.
Materialized views: Materialized views provide significantly faster query performance for repeated and predictable analytical workloads such as dashboards, queries from business intelligence (BI) tools, and ELT (Extract, Load, Transform) data processing. Using materialized views, you can store the pre-computed results of queries and efficiently maintain them by incrementally processing the latest changes made to the source tables. Subsequent queries referencing the materialized views use the pre-computed results to run much faster, and automatic refresh and query rewrite capabilities to simplify and automate the usage of materialized views. Materialized views can be created based on one or more source tables using filters, projections, inner joins, aggregations, grouping, functions, and other SQL constructs.
Scalability: The compute and storage capacity of on-premises data warehouses are limited by the constraints of the on-premises hardware. Redshift gives you the ability to scale compute and storage as needed to meet changing workloads.
Automatic Table Optimization (ATO) is a self-tuning capability helps you achieve the performance benefits of sort and distribution keys without manual effort. ATO continuously observes how queries interact with tables, and uses machine learning to select the best sort and distribution keys to optimize performance for the cluster’s workload. If Redshift determines that applying a key will improve cluster performance, tables will be automatically altered within hours without requiring administrator intervention. Optimizations made by the ATO feature have shown to increase cluster performance by 24% and 34% using the 3TB and 30TB TPC-DS benchmark, respectively, versus a cluster without ATO. Additional features like Automatic Vacuum Delete, Automatic Table Sort, and Automatic Analyze eliminate the need for manual maintenance and tuning of Redshift clusters to get the best performance for new clusters and production workloads.
Amazon Redshift Advisor develops customized recommendations to increase performance and optimize costs by analyzing your workload and usage metrics for your cluster. Sign in to the Amazon Redshift console to view Advisor recommendations. For more information, see Working with recommendations from Amazon Redshift Advisor.
Q: How do I get started with Amazon Redshift?
You can sign up and get started within minutes from the Amazon Redshift detail page or via the AWS Management Console. If you don't already have an AWS account, you'll be prompted to create one. Visit the Getting Started page to see how to try Amazon Redshift for free.
Q: How do I create and access an Amazon Redshift data warehouse cluster?
You can easily create an Amazon Redshift data warehouse cluster by using the AWS Management Console or the Amazon Redshift APIs. You can start with a single node, 160GB data warehouse and scale all the way to petabytes or more with a few clicks in the AWS Console or a single API call.
The single node configuration, which is best suited for evaluation or development/test workloads, enables you to get started with Amazon Redshift quickly and cost-effectively and scale up to a multi-node configuration as your needs grow. A Redshift data warehouse cluster can contain from 1-128 compute nodes, depending on the node type. For the latest generation node type, RA3, the minimum number of nodes is two. For details, please see our documentation.
The multi-node configuration requires a leader node that manages client connections and receives queries, and two compute nodes that store data and perform queries and computations. The leader node, which is the same size as the compute node, is provisioned for you automatically and you are not charged for it.
Simply specify your preferred Availability Zone (optional), the number of nodes, node types, a master name and password, security groups, your preferences for backup retention, and other system settings. Once you've chosen your desired configuration, Amazon Redshift will provision the required resources and set up your data warehouse cluster.
Once your data warehouse cluster is available, you can retrieve its endpoint and JDBC and ODBC connection string from the AWS Management Console or by using the Redshift APIs. You can then use this connection string with your favorite database tool, programming language, or Business Intelligence (BI) tool. You will need to authorize network requests to your running data warehouse cluster. For a detailed explanation, please refer to our Getting Started Guide.
Q: What is the maximum storage capacity per compute node? What is the recommended amount of data per compute node for optimal performance?
You can create a cluster using either RA3, DC, or DS node types. RA3 node types enable you to scale and pay for compute and storage independently. You choose the number of instances you need based on performance requirements, and only pay for the managed storage that you use.
RA3 node types are available in three sizes, RA3.16XL, RA3.4XL, and RA3.XLPLUS. Each RA3.16XL node has 48 vCPUs, 384 GiB of memory, and support 8 GB/s IO. Both RA3.16XL and RA3.4XL clusters run with a minimum of two nodes and the minimum sized two node RA3.16XL or RA3.4XL cluster offer 128 TB of managed storage. The managed storage quota for both RA3.16XL and RA3.4XL per node is 64 TB. The RA3.16XL clusters can scale up-to 128 nodes which allows building a cluster with up to 8 petabytes in managed storage. An RA3.4XL node has 12 vCPUs, 96 GiB of memory, and support 2 GB/s IO. The RA3.4XL clusters can scale up-to 64 nodes which allows building a cluster with up to 4 petabytes of managed storage. An RA3.XLPLUS node has 4vCPU, 32GiB of memory, and support 650 MB IO. RA3.XLPLUS clusters can scale up to 32 nodes which allows building a cluster up to 5 petabytes of managed storage. Note: All managed storage sizes mentioned here are for compressed data. Redshift compresses data 3-4X so uncompressed data sizes are 3-4x larger than mentioned here.
DC node types are also available in two sizes. The Large has 160GB of SSD storage, two Intel Xeon E5-2670v2 (Ivy Bridge) virtual cores and 15GiB of RAM. The Eight Extra Large is 16 times bigger with 2.56TB of SSD storage, 32 Intel Xeon E5-2670v2 virtual cores, and 244GiB of RAM. You can get started with a single DC2.Large node for $0.25 per hour and scale all the way up to 128 8XL nodes with 326TB of SSD storage, 3,200 virtual cores, and 24TiB of RAM.
DS node types are available in two sizes, Extra Large and Eight Extra Large. The Extra Large (XL) has three HDDs with a total of two TB of magnetic storage, whereas Eight Extra Large (8XL) has 24 HDDs with a total of 16TB of magnetic storage. DS2.8XLarge has 36 Intel Xeon E5-2676 v3 (Haswell) virtual cores and 244GiB of RAM, and DS2.XL has four Intel Xeon E5-2676 v3 (Haswell) virtual cores, and 31GiB of RAM.
Please see our pricing page for more details.
Q: When would I use Amazon Redshift vs. Amazon RDS?
Both Amazon Redshift and Amazon RDS enable you to run traditional relational databases in the cloud while offloading database administration. Customers use Amazon RDS databases primarily for online-transaction processing (OLTP) workload while Redshift is used primarily for reporting and analytics. OLTP workloads require quickly querying specific information and support for transactions like insert, update, and delete and are best handled by Amazon RDS. Amazon Redshift harnesses the scale and resources of multiple nodes and uses a variety of optimizations to provide order of magnitude improvements over traditional databases for analytic and reporting workloads against very large data sets. Amazon Redshift provides an excellent scale-out option as your data and query complexity grows if you want to prevent your reporting and analytic processing from interfering with the performance of your OLTP workload. Now, with the new Federated Query feature, you can easily query data across your Amazon RDS or Aurora database services with Amazon Redshift.
Q: When would I use Amazon Redshift or Redshift Spectrum vs. Amazon EMR?
You should use Amazon EMR if you use custom code to process and analyze extremely large datasets with big data processing frameworks such as Apache Spark, Hadoop, Presto, or Hbase. Amazon EMR gives you full control over the configuration of your clusters and the software you install on them.
Data warehouses like Amazon Redshift are designed for a different type of analytics altogether. Data warehouses are designed to pull together data from lots of different sources, like inventory, financial, and retail sales systems. In order to ensure that reporting is consistently accurate across the entire company, data warehouses store data in a highly structured fashion. This structure builds data consistency rules directly into the tables of the database. Amazon Redshift is the best service to use when you need to perform complex queries on massive collections of structured and semi-structured data and get fast performance.
While the Redshift Spectrum feature is great for running queries against data in Amazon Redshift and S3, it really isn’t a fit for the types of use cases that enterprises typically ask from processing frameworks like Amazon EMR. Amazon EMR goes far beyond just running SQL queries. Amazon EMR is a managed service that lets you process and analyze extremely large data sets using the latest versions of popular big data processing frameworks, such as Spark, Hadoop, and Presto, on fully customizable clusters. With Amazon EMR, you can run a wide variety of scale-out data processing tasks for applications such as machine learning, graph analytics, data transformation, streaming data, and virtually anything you can code.
You can use Redshift Spectrum with EMR. Redshift Spectrum uses the same approach to store table definitions as Amazon EMR. Redshift Spectrum can support the same Apache Hive Metastore used by Amazon EMR to locate data and table definitions. If you’re using Amazon EMR and have a Hive Metastore already, you just have to configure your Amazon Redshift cluster to use it. You can then start querying that data right away along with your Amazon EMR jobs. Therefore, if you’re already using EMR to process a large data store, you can use Redshift Spectrum to query that data at the same time without interfering with your Amazon EMR jobs.
Query services, data warehouses, and complex data processing frameworks all have their place, and they are used for different things. You just need to choose the right tool for the job.
Q: When should I use Amazon Athena vs. Redshift Spectrum?
Amazon Athena is the simplest way to give any employee the ability to run ad-hoc queries on data in Amazon S3. Athena is serverless, so there is no infrastructure to setup or manage, and you can start analyzing your data immediately.
If you have frequently accessed data that needs to be stored in a consistent, highly structured format, then you should use a data warehouse like Amazon Redshift. This gives you the flexibility to store your structured, frequently accessed data in Amazon Redshift, and use Redshift Spectrum to extend your Amazon Redshift queries out to data in your Amazon S3 data lake. This gives you the freedom to store your data where you want, in the format you want, and have it available for processing when you need.
Q: Why should I use Amazon Redshift instead of running my own MPP data warehouse cluster on Amazon EC2?
Amazon Redshift automatically handles many of the time-consuming tasks associated with managing your own data warehouse, including:
Setup: With Amazon Redshift, you simply create a data warehouse cluster, define your schema, and begin loading and querying your data. You don’t have to manage provisioning, configuration or patching.
Data Durability: Amazon Redshift replicates your data within your data warehouse cluster and continuously backs up your data to Amazon S3, which is designed for eleven nines of durability. Amazon Redshift mirrors each drive's data to other nodes within your cluster. If a drive fails, your queries will continue with a slight latency increase while Redshift rebuilds your drive from replicas. In case of node failure(s), Amazon Redshift automatically provisions new node(s) and begins restoring data from other drives within the cluster or from Amazon S3. It prioritizes restoring your most frequently queried data so your most frequently executed queries will become performant quickly.
Scaling: You can add or remove nodes from your Amazon Redshift data warehouse cluster with a single API call or via a few clicks in the AWS Management Console as your capacity and performance needs change. You can also schedule your scaling and resize operations by using the scheduler capability in Redshift.
Automatic Updates and Patching: Amazon Redshift automatically applies upgrades and patches your data warehouse so you can focus on your application and not on its administration.
Exabyte Scale Query Capability: Redshift Spectrum enables you to run queries against exabytes of data in Amazon S3. There is no loading or ETL required. Even if you don’t store any of your data in Amazon Redshift, you can still use Redshift Spectrum to query datasets as large as an exabyte in Amazon S3.
Billing
Q: How will I be charged and billed for my use of Amazon Redshift?
You pay only for what you use, and there are no minimum or setup fees. Amazon Redshift supports the ability to pause and resume a cluster, allowing you to easily suspend on-demand billing while the cluster is not being used. For example, a cluster used for development can have compute billing suspended when not in use. While the cluster is paused, you are only charged for the cluster’s storage. For steady-state production workloads, you can get significant discounts over on-demand pricing by switching to Reserved Instances.
Billing commences for a data warehouse cluster as soon as the data warehouse cluster is available. Billing continues until the data warehouse cluster terminates, which would occur upon deletion or in the event of instance failure. You are billed based on the following:
Compute node hours: Compute node hours are the total number of hours you run across all your compute nodes for the billing period. Node usage hours are billed for each hour your data warehouse cluster is running in an available state. If you no longer wish to be charged for your data warehouse cluster, you must terminate it to avoid being billed for additional node hours. Partial node hours consumed are billed as full hours. You are billed for 1 unit per node per hour, so a 3-node data warehouse cluster running persistently for an entire month would incur 2,160 instance hours. You will not be charged for leader node hours; only compute nodes will incur charges.
Managed storage: You pay for data stored in managed storage at a fixed GB-month rate for your region. Managed storage comes exclusively with RA3 node types and you pay the same low rate for Redshift managed storage regardless of data size. Usage of managed storage is calculated hourly based on the total data present in the managed storage. You can monitor the amount of data in your RA3 cluster via Amazon CloudWatch or the AWS Management Console. You do not pay for any data transfer charges between RA3 nodes and managed storage. Managed storage charges do not include back up storage charges due to automated and manual snapshots. Once the cluster is terminated, you continue to be charged for the retention of your manual backups.
Backup Storage: Backup storage is the storage associated with the snapshots taken for your data warehouse. Increasing your backup retention period or taking additional snapshots increases the backup storage consumed by your data warehouse. Redshift charges for manual snapshots you take using the console, API or CLI. Redshift Automated snapshots, which get created using Redshift's snapshot scheduling feature, are not charged for. Data stored on RA3 clusters is part of Redshift Managed Storage (RMS) and is billed at RMS rates, but manual snapshots taken for RA3 clusters are billed as backup storage at standard Amazon S3 rates outlined on this page. For example, if your RA3 cluster has 10 TB of data and 30 TB of manual snapshots, you would be billed for 10 TB of RMS and 30 TB of backup storage. With dense compute (DC) and dense storage (DS) clusters, storage is included on the cluster and is not billed for separately, but backups are stored externally in S3. Backup storage beyond the provisioned storage size on DC and DS clusters is billed as backup storage at standard Amazon S3 rates. Snapshots are billed until they expire or are deleted, including when the cluster is paused or deleted.
Data transfer: There is no data transfer charge for data transferred to or from Amazon Redshift and Amazon S3 within the same AWS Region. For all other data transfers into and out of Amazon Redshift, you will be billed at standard AWS data transfer rates.
Data scanned: With Redshift Spectrum, you are charged for the amount of Amazon S3 data scanned to execute your query. There are no charges for Redshift Spectrum when you’re not running queries. If you store data in a columnar format, such as Parquet or RC, your charges will go down, as Redshift Spectrum will only scan the columns needed by the query, rather than processing entire rows. Similarly, if you compress your data, using one of Redshift Spectrum’s supported formats, your costs will also go down. You pay the standard Amazon S3 rates for data storage and Amazon Redshift instance rates for the cluster used.
Concurrency Scaling: With Concurrency Scaling, Redshift automatically adds transient capacity to provide consistently fast performance, even with thousands of concurrent users and queries. There are no resources to manage, no upfront costs, and you are not charged for the startup or shutdown time of the transient clusters. You can accumulate one hour of concurrency scaling cluster credits every 24 hours while your main cluster is running. You are charged the per-second on-demand rate for a concurrency scaling cluster used in excess of the free credits - only when it's serving your queries - with a one-minute minimum charge each time a concurrency scaling cluster is activated. The per-second on-demand rate is based on the type and number of nodes in your Amazon Redshift cluster.
Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax. For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. Learn more.
For Amazon Redshift pricing information, please visit the Amazon Redshift pricing page.
Data integration and loading
Q: How do I load data into my Amazon Redshift data warehouse?
You can load data into Amazon Redshift from a range of data sources including Amazon S3, Amazon RDS, Amazon DynamoDB, Amazon EMR, AWS Glue, AWS Data Pipeline and or any SSH-enabled host on Amazon EC2 or on-premises. Amazon Redshift attempts to load your data in parallel into each compute node to maximize the rate at which you can ingest data into your data warehouse cluster. Clients can connect to Amazon Redshift using ODBC or JDBC and issue 'insert' SQL commands to insert the data. Please note this is slower than using S3 or DynamoDB since those methods load data in parallel to each compute node while SQL insert statements load via the single leader node. For more details on loading data into Amazon Redshift, please view our Getting Started Guide.
Q: How do I load data from my existing Amazon RDS, Amazon EMR, Amazon DynamoDB, and Amazon EC2 data sources to Amazon Redshift?
You can use our COPY command to load data in parallel directly to Amazon Redshift from Amazon EMR, Amazon DynamoDB, or any SSH-enabled host. Redshift Spectrum also enables you to load data from Amazon S3 into your cluster with a simple INSERT INTO command. This could enable you to load data from various formats such as Parquet and RC into your cluster. Note that if you use this approach, you will accrue Redshift Spectrum charges for the data scanned from Amazon S3.
In addition, many ETL companies have certified Amazon Redshift for use with their tools, and a number are offering free trials to help you get started loading your data. AWS Data Pipeline provides a high performance, reliable, fault tolerant solution to load data from a variety of AWS data sources like Amazon RDS to Redshift. You can use AWS Data Pipeline to specify the data source, desired data transformations, and then execute a pre-written import script to load your data into Amazon Redshift. In addition, AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analytics. You can create and run an AWS Glue ETL job with a few clicks in the AWS Management Console.
Q: I have a lot of data for initial loading into Amazon Redshift. Transferring via the Internet would take a long time. How do I load this data?
You can use AWS Snowball to transfer the data to Amazon S3 using portable storage devices. In addition, you can use AWS Direct Connect to establish a private network connection between your network or data center and AWS. You can choose 1Gbit/sec or 10Gbit/sec connection ports to transfer your data.
Security
Q: How does Amazon Redshift keep my data secure?
Amazon Redshift supports industry-leading security with built-in AWS IAM integration, identity federation for single-sign on (SSO), multi-factor authentication, column-level access control, Amazon Virtual Private Cloud (Amazon VPC), and provides built-in AWS KMS integration to protect your data in transit and at rest. Amazon Redshift encrypts and keeps your data secure in transit and at rest using industry-standard encryption techniques. To keep data secure in transit, Amazon Redshift supports SSL-enabled connections between your client application and your Redshift data warehouse cluster. To keep your data secure at rest, Amazon Redshift encrypts each block using hardware-accelerated AES-256 as it is written to disk. This takes place at a low level in the I/O subsystem, which encrypts everything written to disk, including intermediate query results. The blocks are backed up as is, which means that backups are encrypted as well. By default, Amazon Redshift takes care of key management but you can choose to manage your keys through AWS Key Management Service. All Amazon Redshift security features are offered at no additional costs. Redshift Spectrum supports Amazon S3’s Server Side Encryption (SSE) using your account’s default key managed used by the AWS Key Management Service (KMS).
Q: Does Redshift support granular access controls like column level security?
Yes. Granular column level security controls ensure users see only the data they should have access to. Amazon Redshift supports column level access control for local tables so you can control access to individual columns of a table or view by granting / revoking column level privileges to a user or a user-group. Redshift is integrated with AWS Lake Formation, ensuring Lake Formation’s column level access controls are also enforced for Redshift queries on the data in the data lake.
Q: Does Amazon Redshift support data masking or data tokenization?
Amazon Lambda user-defined functions (UDFs) enable you to use an AWS Lambda function as a UDF in Amazon Redshift and invoke it from Redshift SQL queries. This functionality enables you to write custom extensions for your SQL query to achieve tighter integration with other services or third-party products. You can write Lambda UDFs to enable external tokenization, data masking, identification or de-identification of data by integrating with vendors like Protegrity, and protect or unprotect sensitive data based on a user’s permissions and groups, in query time.
Q: Does Redshift support single sign-on?
Yes. Customers who want to use their corporate identity providers such as Microsoft Azure Active Directory, Active Directory Federation Services, Okta, Ping Federate, or other SAML compliant identity providers can configure Amazon Redshift to provide single-sign on.
Q: How does Redshift support single sign-on with Microsoft Azure Active Directory?
You can sign-on to Amazon Redshift cluster with Microsoft Azure Active Directory (AD) identities. This allows you to be able to sign-on to Redshift without duplicating Azure Active Directory identities in Redshift.
Q: Does Amazon Redshift support multi-factor authentication (MFA)?
Yes. You can use multi-factor authentication (MFA) for additional security when authenticating to your Amazon Redshift cluster.
Q: Can I use Amazon Redshift in Amazon Virtual Private Cloud (Amazon VPC)?
Yes, you can use Amazon Redshift as part of your VPC configuration. With Amazon VPC, you can define a virtual network topology that closely resembles a traditional network that you might operate in your own data center. This gives you complete control over who can access your Amazon Redshift data warehouse cluster. You can use Redshift Spectrum with an Amazon Redshift cluster that is part of your VPC.
Q: Can I access my Amazon Redshift compute nodes directly?
No. Your Amazon Redshift compute nodes are in a private network space and can only be accessed from your data warehouse cluster's leader node. This provides an additional layer of security for your data.
Availability and durability
Q: What happens to my data warehouse cluster availability and data durability if a drive on one of my nodes fails?
Amazon Redshift will automatically detect and replace a failed node in your data warehouse cluster. The data warehouse cluster will be unavailable for queries and updates until a replacement node is provisioned and added to the DB. Amazon Redshift makes your replacement node available immediately and loads your most frequently accessed data from S3 first to allow you to resume querying your data as quickly as possible. Single node clusters do not support data replication. In the event of a drive failure, you will need to restore the cluster from snapshot on S3. We recommend using at least two nodes for production.
Q: What happens to my data warehouse cluster availability and data durability in the event of individual node failure?
Q: What happens to my data warehouse cluster availability and data durability if my data warehouse cluster's Availability Zone (AZ) has an outage?
If your Amazon Redshift data warehouse cluster's Availability Zone becomes unavailable, Amazon Redshift will automatically move your cluster to another AWS Availability Zone (AZ) without any data loss or application changes. To activate this, you must enable the relocation capability in your cluster configuration settings.
Q: Does Amazon Redshift support Multi-AZ Deployments?
Currently, Amazon Redshift only supports Single-AZ deployments. You can run data warehouse clusters in multiple AZ's by loading data into two Amazon Redshift data warehouse clusters in separate AZs from the same set of Amazon S3 input files. With Redshift Spectrum, you can spin up multiple clusters across AZs and access data in Amazon S3 without having to load it into your cluster. In addition, you can also restore a data warehouse cluster to a different AZ from your data warehouse cluster snapshots.
Backup and restore
Q: How does Amazon Redshift backup my data? How do I restore my cluster from a backup?
Amazon Redshift replicates all your data within your data warehouse cluster when it is loaded and also continuously backs up your data to Amazon S3. Amazon Redshift always attempts to maintain at least three copies of your data (the original and replica on the compute nodes, and a backup in Amazon S3). Redshift can also asynchronously replicate your snapshots to S3 in another region for disaster recovery.
By default, Amazon Redshift enables automated backups of your data warehouse cluster with a 1-day retention period. You can configure this to be as long as 35 days.
Free backup storage is limited to the total size of storage on the nodes in the data warehouse cluster and only applies to active data warehouse clusters. For example, if you have total data warehouse storage of 8TB, we will provide at most 8TB of backup storage at no additional charge. If you would like to extend your backup retention period beyond one day, you can do so using the AWS Management Console or the Amazon Redshift APIs. For more information on automated snapshots, please refer to the Amazon Redshift Management Guide. Amazon Redshift only backs up data that has changed so most snapshots only use up a small amount of your free backup storage.
When you need to restore a backup, you have access to all the automated backups within your backup retention window. Once you choose a backup from which to restore, we will provision a new data warehouse cluster and restore your data to it.
Q: How do I manage the retention of my automated backups and snapshots?
You can use the AWS Management Console or ModifyCluster API to manage the period of time your automated backups are retained by modifying the RetentionPeriod parameter. If you wish to turn off automated backups altogether, you can set up the retention period to 0 (not recommended).
Q: What happens to my backups if I delete my data warehouse cluster?
When you delete a data warehouse cluster you have the ability to specify whether a final snapshot is created upon deletion. This enables a restore of the deleted data warehouse cluster at a later date. All previously created manual snapshots of your data warehouse cluster will be retained and billed at standard Amazon S3 rates, unless you choose to delete them.
Scalability
Q: How do I scale the size and performance of my Amazon Redshift data warehouse cluster?
If you would like to increase query performance or respond to CPU, memory or I/O over-utilization, you can increase the number of nodes within your data warehouse cluster using Elastic Resize via the AWS Management Console or the ModifyCluster API. When you modify your data warehouse cluster, your requested changes will be applied immediately. Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge via the AWS Management Console or Amazon CloudWatch APIs. You can also add additional, user-defined metrics via Amazon CloudWatch custom metric functionality.
With the Concurrency Scaling feature, you can support virtually unlimited concurrent users and concurrent queries, with consistently fast query performance. When concurrency scaling is enabled, Amazon Redshift automatically adds additional cluster capacity when you need it to process an increase in concurrent read queries.
With Redshift Spectrum, you can run multiple Amazon Redshift clusters accessing the same data in Amazon S3. You can use different clusters for different use cases. For example, you can use one cluster for standard reporting and another for data science queries. Your marketing team can use their own clusters different from your operations team. Redshift Spectrum automatically distributes the execution of your query to several Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3, and pulls results back into your Amazon Redshift cluster for any remaining processing.
Q: Will my data warehouse cluster remain available during scaling?
It depends. When you using the Concurrency Scaling feature, the cluster is fully available for read and write during concurrency scaling. With Elastic resize, the cluster is unavailable for four to eight minutes of the resize period. With the Redshift RA3 storage elasticity in managed storage, the cluster is fully available and data is automatically moved between managed storage and compute nodes.
Q: What is Amazon Redshift data sharing?
Amazon Redshift data sharing enables a secure and easy way to share live data across Redshift. Data sharing improves the agility of organizations by giving them instant, granular and high-performance access to data inside any Redshift cluster without the need to copy or move it and provides live access to the data so that users can see the most up-to-date and consistent information as it is updated in the cluster. With data sharing, you can rapidly onboard new analytics workloads and provision them with isolated compute resources to meet your workload-specific performance SLAs while allowing access to common datasets. In addition to sharing data within organizations, data sharing also enables secure and governed collaboration across organizations, and with external parties. Common use cases for data sharing include setting up a central ETL cluster to share data with many BI clusters to provide read workload isolation and chargeback, offering data as a service and sharing data with external consumers, multiple business groups within an organization sharing and collaborating on data to gain differentiated insights, and sharing data between development, test and production environments. To learn more and get started, visit the Redshift documentation.
Q: What are cross-database queries in Redshift?
With cross-database queries, you can seamlessly query and join data from any Redshift database that you have access to, regardless of which database you are connected to. This can include databases local on the cluster and also shared datasets made available from remote clusters. Cross-database queries give you flexibility to organize data as separate databases to support multi-tenant configurations.
Q: When should customers use concurrency scaling and when should they use data sharing?
Data sharing and concurrency scaling are complementary features. With concurrency scaling, Redshift allows you to auto-scale one or more workloads in a single cluster to handle high concurrency and query spikes. Redshift elastically and automatically spins up the capacity in seconds to deal with the bursts of user activity and brings it down when activity subsides. Applications continue to interact with Redshift using a single application end point. Data sharing allows you to scale to diverse workloads with multi-cluster, multi-account deployments. This enabled workload isolation and charge-ability, cross-group collaboration in de-centralized environments and ability to offer data as a service to internal and external stakeholders. You can enable concurrency scaling on both data sharing producer clusters and consumer clusters.
Concurrency
Q: How do I manage resources to ensure that my Redshift cluster can provide consistently fast performance during periods of high concurrency?
A typical data warehouse has significant variance in concurrent query usage over the course of a day. It is more cost-effective to add resources just for the period during which they are required rather than provisioning to peak demand. Amazon Redshift handles this automatically on your behalf.
Concurrency Scaling is a feature in Amazon Redshift that provides consistently fast query performance, even with thousands of concurrent queries. With this feature, Amazon Redshift automatically adds transient capacity when needed to handle heavy demand. Amazon Redshift automatically routes queries to scaling clusters, which are provisioned in seconds and begin processing queries immediately.
This feature is free for most customers. Each Amazon Redshift cluster earns up to one hour of free Concurrency Scaling credits per day. This gives you predictability in your month-to-month cost, even during periods of fluctuating analytical demand.
Q: What is Elastic Resize and how is it different from Concurrency Scaling?
Elastic Resize adds or removes nodes from a single Redshift cluster within minutes to manage its query throughput. For example, an ETL workload for certain hours in a day or month-end reporting may need additional Redshift resources to complete on time. Concurrency Scaling adds additional cluster resources to increase the overall query concurrency.
Q: Can I access the Concurrency Scaling clusters directly?
No. Concurrency Scaling is a massively scalable pool of Redshift resources and customers do not have direct access.
Querying and analytics
Q: Are Amazon Redshift and Redshift Spectrum compatible with my preferred business intelligence software package and ETL tools?
Yes, Amazon Redshift uses industry-standard SQL and is accessed using standard JDBC and ODBC drivers. You can download Amazon Redshift custom JDBC and ODBC drivers from the Connect Client tab of the Redshift Console. We have validated integrations with popular BI and ETL vendors, a number of which are offering free trials to help you get started loading and analyzing your data. You can also go to the AWS Marketplace to deploy and configure solutions designed to work with Amazon Redshift in minutes.
Redshift Spectrum supports all Amazon Redshift client tools. The client tools can continue to connect to the Amazon Redshift cluster endpoint using ODBC or JDBC connections. No changes are required.
You use exactly the same query syntax and have the same query capabilities to access tables in Redshift Spectrum as you have for tables in the local storage of your Redshift cluster. External tables are referenced using the schema name defined in the CREATE EXTERNAL SCHEMA command where they were registered.
Q: What data formats and compression formats does Redshift Spectrum support?
Redshift Spectrum currently supports many open source data formats, including Avro, CSV, Grok, Amazon Ion, JSON, ORC, Parquet, RCFile, RegexSerDe, Sequence, Text, and TSV.
Redshift Spectrum currently supports Gzip and Snappy compression.
Q: What happens if a table in my local storage has the same name as an external table?
Just like with local tables, you can use the schema name to pick exactly which one you mean by using schema_name.table_name in your query.
Q: I use a Hive Metastore to store metadata about my S3 data lake. Can I use Redshift Spectrum?
Yes. The CREATE EXTERNAL SCHEMA command supports Hive Metastores. We do not currently support DDL against the Hive Metastore.
Q: How do I get a list of all external database tables created in my cluster?
You can query the system table SVV_EXTERNAL_TABLES to get that information.
Q: Does Redshift support the ability to use Machine Learning with SQL?
Yes, the Amazon Redshift ML (preview) feature makes it easy for SQL users to create, train, and deploy machine learning (ML) models using familiar SQL commands. Amazon Redshift ML allows customers to leverage their data in Amazon Redshift with Amazon SageMaker, a fully managed machine learning service.
Q: Does Amazon Redshift provide an API to query data?
Amazon Redshift provides a Data API that enables you to painlessly access data from Amazon Redshift with all types of traditional, cloud-native, and containerized, serverless web services-based and event-driven applications. The Data API simplifies access to Amazon Redshift because you don’t need to configure drivers and managing database connections. Instead, you can run SQL commands to an Amazon Redshift cluster by simply calling a secured API endpoint provided by the Data API. The Data API takes care of managing database connections and buffering data. The Data API is asynchronous, so you can retrieve your results later. Your query results are stored for 24 hours.
Q: What types of credentials can I use with Amazon Redshift Data API?
The Data API supports both IAM credentials and using a secret key from AWS Secrets Manager. The Data API federates AWS Identity and Access Management (IAM) credentials so you can use identity providers like Okta or Azure Active Directory or database credentials stored in Secrets Manager without passing database credentials in API calls.
Q: Can I use Amazon Redshift Data API from AWS CLI?
Yes, you can use the Data API from AWS CLI using the aws redshift-data command line option.
Q: Is the Redshift Data API integrated with other AWS services?
You can use the Data API from other services such as AWS Lambda, AWS Cloud9, AWS AppSync and Amazon EventBridge.
Q: Do I have to pay separately for using the Amazon Redshift Data API?
No, there is no separate charge for using the Data API.
Monitoring
Q: How do I monitor the performance of my Amazon Redshift data warehouse cluster?
Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge via the AWS Management Console or Amazon CloudWatch APIs. You can also add additional, user-defined metrics via Amazon CloudWatch’s custom metric functionality. The AWS Management Console provides a monitoring dashboard that helps you monitor the health and performance of all your clusters. Amazon Redshift also provides information on query and cluster performance via the AWS Management Console. This information enables you to see which users and queries are consuming the most system resources to diagnose performance issues by viewing query plans and execution statistics. In addition, you can see the resource utilization on each of your compute nodes to ensure that you have data and queries that are well-balanced across all nodes.
Maintenance
Q: What is a maintenance window? Will my data warehouse cluster be available during software maintenance?
Amazon Redshift periodically performs maintenance to apply fixes, enhancements and new features to your cluster. You can change the scheduled maintenance windows by modifying the cluster, either programmatically or by using the Redshift Console. During these maintenance windows, your Amazon Redshift cluster is not available for normal operations. For more information about maintenance windows and schedules by region, see Maintenance Windows in the Amazon Redshift Management Guide.
Learn more about Amazon Redshift pricing
Visit the pricing page
Ready to build?
Get started with Amazon Redshift
Have more questions?
Contact us
Page Content